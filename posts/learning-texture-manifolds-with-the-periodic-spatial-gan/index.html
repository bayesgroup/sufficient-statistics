<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " vocab="http://ogp.me/ns" lang="ru">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Learning Texture Manifolds with the Periodic Spatial GAN | Codename 'Sufficient Statistics'</title>
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/lanyon.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/custom.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
<link rel="canonical" href="http://bayesgroup.github.io/sufficient-statistics/posts/learning-texture-manifolds-with-the-periodic-spatial-gan/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Айбек Аланов">
<link rel="prev" href="../treeqn-and-atreec-differentiable-tree-planning-for-deep-reinforcement-learning/" title="TreeQN And ATreeC: Differentiable Tree Planning For Deep Reinforcement Learning" type="text/html">
<meta property="og:site_name" content="Codename 'Sufficient Statistics'">
<meta property="og:title" content="Learning Texture Manifolds with the Periodic Spatial GAN">
<meta property="og:url" content="http://bayesgroup.github.io/sufficient-statistics/posts/learning-texture-manifolds-with-the-periodic-spatial-gan/">
<meta property="og:description" content="Предыстория
Есть такая задача - генерация текстур (texture synthesis). Она состоит в том, что, имея образец текстуры, мы хотим научиться генерировать ее копии. А именно, такие картинки, которые сохран">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-12-12T04:41:57+03:00">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="gan">
<meta property="article:tag" content="mathjax">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>
    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
            styles, `#sidebar-checkbox` for behavior. -->
    <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"><!-- Toggleable sidebar --><div class="sidebar" id="sidebar">
        <div class="sidebar-item">
            <p>Обзоры не являются официальной позицией группы и предназначены исключительно для внутреннего использования.</p>
        </div>
        
    <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../../authors/">Авторы</a>
        <a class="sidebar-nav-item" href="../../archive.html">Архив</a>
        <a class="sidebar-nav-item" href="../../categories/">Тэги</a>
    
    
    </nav>
</div>

    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          
    <h3 id="brand" class="masthead-title">
      <a href="../../" title="Codename 'Sufficient Statistics'" rel="home">Codename 'Sufficient Statistics'</a>
    </h3>


        </div>
      </div>

      <div class="container content" id="content">
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><div class="paper-link">
        <a href="https://arxiv.org/abs/1705.06566">Paper</a>
    </div>
    <header><h1 class="post-title p-name entry-title" itemprop="headline name"><a href="." class="u-url">Learning Texture Manifolds with the Periodic Spatial GAN</a></h1>

        
        <ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/deep-learning/" rel="tag">deep learning</a></li>
            <li><a class="tag p-category" href="../../categories/gan/" rel="tag">gan</a></li>
        </ul></header><div class="e-content entry-content" itemprop="articleBody text">
    <h1 id="предыстория">Предыстория</h1>
<p>Есть такая задача - <em>генерация текстур</em> (texture synthesis). Она состоит в том, что, имея образец текстуры, мы хотим научиться генерировать ее копии. А именно, такие картинки, которые сохраняют локальную геометрию образца, но в масштабе всего изображения могут отличаться. Эту задачу долгое время пытались решать следующим образом. Для образца <span class="math inline">\(X\)</span> считали очень много эвристических статистик <span class="math inline">\(f_1(X), \dots, f_n(X)\)</span>. После этого находили такие изображения <span class="math inline">\(Y_1, \dots, Y_k\)</span>, что расстояние <span class="math inline">\(\sum\limits_{i=1}^n||f_i(X) - f_i(Y_j)||^2\)</span> между статистиками <span class="math inline">\(X\)</span> и <span class="math inline">\(Y_j\)</span> была достаточно маленькой.</p>
<p>В статье <a href="http://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf">Texture Synthesis Using Convolutional Neural Networks (2015)</a> впервые используются сверточные сети для решения этой задачи. Основная идея этой статьи в том, что вместо упомянутых выше статистик берутся другие статистики, основанные на выходах нейросети. А именно, берется предобученная VGG-19 сеть без полносвязных слоев, для входной текстуры считаются выходы сверточных слоев и для этих выходов считается матрица Грамма. То есть для каждого слоя мы получаем свои матрицы Грамма <span class="math inline">\(G_1(X), \dots, G_n(X)\)</span>. И это будут наши новые статистики. Прорыв этой статьи был в том, что генерировались текстуры высокого качества, лучше, чем было раньше. Основной недостаток этой статьи в том, что для генерации текстур <span class="math inline">\(Y_1, \dots, Y_k\)</span> требуется много времени, так как для каждой текстуры решается оптимизационная задача <span class="math inline">\(\min\limits_{Y_j}\;\sum\limits_{i=1}^n||G_i(X) - G_i(Y_j)||^2\)</span> (необходимо несколько итераций градиентного спуска <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>).</p>
<p>В двух статьях (<a href="http://proceedings.mlr.press/v48/ulyanov16.pdf">первая</a> (2016) и <a href="https://arxiv.org/pdf/1603.08155.pdf">вторая</a> (2016)) решили проблему с временем генерации текстур. Основная идея состоит в том, что вместо того, чтобы каждый раз при генерации текстуры решать оптимизационную задачу, один раз обучается сверточная нейронная сеть, которая на вход принимает вектор шума, а на выходе генерирует желаемые текстуры <span class="math inline">\(Y_1, \dots, Y_k\)</span>, минимизирующие функционал <span class="math inline">\(\min\limits_{Y_j}\;\sum\limits_{i=1}^n||G_i(X) - G_i(Y_j)||^2\)</span>.</p>
<p>В следующей статье <a href="https://arxiv.org/pdf/1611.08207.pdf">Texture Synthesis with Spatial Generative Adversarial Networks (2017)</a> предлагается обучить GAN для генерации текстур без использования предобученной VGG-19 сети. Архитектура предложенной GAN-сети похожа на архитектуру <a href="https://arxiv.org/pdf/1511.06434.pdf">DCGAN</a> за тем исключением, что в ней нет полносвязных слоев и на вход подается не вектор шума, а 3-мерный тензор шума.</p>
<p><img src="../../post-images/learning-texture-manifolds-with-the-periodic-spatial-gan/sgan.png" class="large"></p>
<p>Так как сеть полностью состоит из сверточных слоев, это позволяет произвольно менять две пространственные координанты шума (<span class="math inline">\(l\)</span> и <span class="math inline">\(m\)</span> на картинке), тем самым меняя разрешение генерируемых текстур.</p>
<p>Основные достоинства этой модели в том, что у нее высокая скорость генерации текстур (выше, чем у всех предыдущих моделей), качество текстур так же высоко, как и у других моделей, возможность генерации текстур с высоким разрешением. Также данный метод в отличие от предыдущих подходов позволяет получать текстуры высокого качества для картинок из любой области. Для остальных подходов это не так, поскольку они полагаются на веса VGG-19 сети, которые были обучены на ImageNet. Понятно, что для картинок, которых нет в ImageNet, предыдущие модели могут работать плохо.</p>
<h1 id="мотивация">Мотивация</h1>
<p>Как было сказано выше, модель <a href="https://arxiv.org/pdf/1611.08207.pdf">SGAN</a> предлагает новый довольно успешный метод генерации текстур, основанный на обучении GAN с определенной архитектурой. Основные недостатки этой модели заключаются в том, что она плохо работает с текстурами, в которых есть периодичность. Также если обучить данную модель на каком-нибудь датасете, в котором есть несколько разных текстур, то после обучения она будет генерировать картинки, которые не будут относится ни к одной из существующих текстур, а будут являться их смесями. Нам хотелось бы, чтобы генерировались не смеси, а примеры разных текстур.</p>
<p>Статья, которая разбирается в этой заметке и которая написана теми же авторами, что и SGAN, решает две проблемы, о которых мы сказали выше. Эта статья называется <a href="https://arxiv.org/pdf/1705.06566.pdf">Learning Texture Manifolds with the Periodic Spatial GAN (2017)</a>. В ней предлагается использовать такую же архитектуру, что и в SGAN, за тем исключением, что каждый элемент тензора шума генерируется не независимо, а исходя из определенной структуры шума, которая позволяет выучивать периодические текстуры и также множество различных текстур.</p>
<h1 id="структура-шума">Структура шума</h1>
<p>Мы делим 3-мерный тензор шума на три части, у каждой из которых есть свои функции.</p>
<p><img src="../../post-images/learning-texture-manifolds-with-the-periodic-spatial-gan/psgan.png" class="large"></p>
<p>Локальные координаты (local dimensions - на рисунке серый цвет) - часть тензора, в которой все элементы генерируются независимо. Она отвечает за разнообразие генерируемых текстур.</p>
<p>Глобальные координаты (global dimensions - на рисунке фиолетовый цвет) - часть тензора, в которой один раз генерируется вектор шума <span class="math inline">\(z \in \mathbb{R}^{d^g}\)</span>, который присваивается всем <span class="math inline">\(L\cdot M\)</span> векторам данного тензора. Данная часть позволяет модели довольно легко разбить множество тензоров шума на несколько областей и из каждой области генерировать текстуры определенного типа. То есть это позволяет обучаться на множестве из нескольких разных текстур.</p>
<p>Пространственно-периодические координаты (spatially periodic dimensions - на рисунке желтый цвет) - часть тензора, элементы которой генерируются следующим образом: <span class="math inline">\(z_{ijt} = \sin\left(k_t^T\begin{pmatrix} i \\ j \end{pmatrix} + \varphi_t\right)\)</span>, где <span class="math inline">\(i = 1, \dots, L, \; j = 1, \dots, M, \; t = 1, \dots, d^{p}\)</span> и <span class="math inline">\(K\)</span> - это <span class="math inline">\(2\times d^p\)</span> матрица коэффициентов, которые обучаются (на рисунке можно видеть, что они связаны с глобальными координатами через полносвязную сеть). Элементы этой матрицы параметризуют направление и значение угла для каждого канала. Смещения углов <span class="math inline">\(\varphi_i\)</span> генерируются случайно и независимо из отрезка <span class="math inline">\([0, 2\pi)\)</span>.</p>
<h1 id="обучение-psgan">Обучение PSGAN</h1>
<p>Обучение PSGAN происходит так же, как и обучение SGAN. Рассмотрим его подробнее. На вход генератору <span class="math inline">\(G\)</span> подается тензор шума <span class="math inline">\(Z\)</span> размера <span class="math inline">\(L\times M\times d\)</span>. Выход генератора <span class="math inline">\(G(Z)\)</span> имеет размер <span class="math inline">\(H\times W\times 3\)</span>. Соответственно дискриминатор <span class="math inline">\(D\)</span> принимает на вход выход генератора <span class="math inline">\(X = G(Z)\)</span> или настоящую картинку <span class="math inline">\(X\)</span> и возвращает матрицу <span class="math inline">\(D(X)\)</span> размера <span class="math inline">\(L\times M\)</span>, каждое значение которой <span class="math inline">\(D_{ij}(X)\)</span> равно вероятности, что соответствующая часть изображения <span class="math inline">\(X\)</span> принадлежит настоящему изображению, а не сгенерированному с помощью <span class="math inline">\(G\)</span>.</p>
<p>Соответственно стандартная функция потери для GAN <span class="math inline">\(V(D, G)\)</span> в этом случае равна <span class="math display">\[
V(D, G) = \dfrac{1}{LM}\sum\limits_{i=1}^L\sum\limits_{j=1}^M \left[ \mathbb{E}_{Z\sim p_Z(Z)} \ln(1 - D_{ij}(G(Z))) + \mathbb{E}_{X'\sim p_{\text{data}}(X)} \ln(D_{ij}(X') \right]
\]</span> Эта функция минимизируется по <span class="math inline">\(G\)</span> и максимизируется по <span class="math inline">\(D\)</span>, <span class="math inline">\(\min\limits_{G}\max\limits_{D}V(D, G)\)</span>.</p>
<p>Так как мы хотим иметь возможность обучаться на датасете из одного изображения-текстуры, то при обучении мы извлекаем из картинки подизображения меньшего размера из случайных мест.</p>
<h1 id="эксперименты">Эксперименты</h1>
<p>В статье довольно много экспериментов, которые показывает различные свойства данной модели.</p>
<p>Во-первых, данная модель отлично выучивает периодические текстуры в отличие от предыдущих моделей. Данный пример, сгенерированный этой моделью, доказывает это:</p>
<p><img src="../../post-images/learning-texture-manifolds-with-the-periodic-spatial-gan/honeycomb.jpg" class="medium"></p>
<p>Во-вторых, данная модель может выучить целое множество различных текстур. Это можно увидеть в следующем эксперименте:</p>
<p><img src="../../post-images/learning-texture-manifolds-with-the-periodic-spatial-gan/manifold.png" class="large"></p>
<p>Здесь мы видим, что PSGAN выучил разные текстуры, которые были на входной картинке, в отличие от двух других методов.</p>
<p>Также авторы показали, что их модель выучивает многообразие текстур, в котором можно из одной текстуры гладко перейти к другой, меняя тензор шума. Это можно увидеть на следующей картинке.</p>
<p><img src="../../post-images/learning-texture-manifolds-with-the-periodic-spatial-gan/morphing.png" class="large"></p>
<h1 id="резюме">Резюме</h1>
<p>Интересная идея с введением структуры в пространстве шума, которая позволяет значительно улучшить качество генерируемых текструр с, например, периодической структурой. Кажется, что это довольно многообещающая идея, которую можно применить к другим задачам. Также довольно интересно, что это позволяет обучаться на множестве из различных текстур.</p>
<section class="footnotes"><hr>
<ol>
<li id="fn1"><p>В реализации к оригинальной статье использовался даже не обычный градиентный спуск, а более эффективные оптимизационные алгоритмы вроде L-BFGS.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol></section>
</div>

    <aside class="post-meta"><a class="post-author" href="../../authors/aibek-alanov/">Айбек Аланов</a>
    <time class="post-date published dt-published" datetime="2017-12-12T04:41:57+03:00" itemprop="datePublished" title="12 декабря 2017">12 декабря 2017</time></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article>
</div>
    </div>
    <label for="sidebar-checkbox" class="sidebar-toggle"></label>
    
    
        <footer id="footer"><p>Contents © 2017         <a href="mailto:info@bayesgroup.ru">BayesGroup</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer><script src="../../assets/js/jquery.min.js"></script><script src="../../assets/js/moment-with-locales.min.js"></script><script src="../../assets/js/fancydates.js"></script><!-- fancy dates --><script>
    moment.locale("ru");
    fancydates(2, "DD.MM.YYYY");
    </script><!-- end fancy dates -->
</body>
</html>
