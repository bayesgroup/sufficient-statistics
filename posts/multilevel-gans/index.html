<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " vocab="http://ogp.me/ns" lang="ru">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Multilevel GANs | Codename 'Sufficient Statistics'</title>
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/poole.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/lanyon.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/custom.css" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
<link rel="canonical" href="http://bayesgroup.github.io/sufficient-statistics/posts/multilevel-gans/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Алексей Умнов">
<link rel="prev" href="../treeqn-and-atreec-differentiable-tree-planning-for-deep-reinforcement-learning/" title="TreeQN And ATreeC: Differentiable Tree Planning For Deep Reinforcement Learning" type="text/html">
<link rel="next" href="../learning-texture-manifolds-with-the-periodic-spatial-gan/" title="Learning Texture Manifolds with the Periodic Spatial GAN" type="text/html">
<meta property="og:site_name" content="Codename 'Sufficient Statistics'">
<meta property="og:title" content="Multilevel GANs">
<meta property="og:url" content="http://bayesgroup.github.io/sufficient-statistics/posts/multilevel-gans/">
<meta property="og:description" content="Статьи:

LapGAN: Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. Denton et. al. 2015
StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversari">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-12-08T09:10:03+03:00">
<meta property="article:tag" content="adversarial networks">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="generative models">
<meta property="article:tag" content="mathjax">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>
    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
            styles, `#sidebar-checkbox` for behavior. -->
    <input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox"><!-- Toggleable sidebar --><div class="sidebar" id="sidebar">
        <div class="sidebar-item">
            <p>Обзоры не являются официальной позицией группы и предназначены исключительно для внутреннего использования.</p>
        </div>
        
    <nav id="menu" role="navigation" class="sidebar-nav"><a class="sidebar-nav-item" href="../../authors/">Авторы</a>
        <a class="sidebar-nav-item" href="../../archive.html">Архив</a>
        <a class="sidebar-nav-item" href="../../categories/">Тэги</a>
    
    
    </nav>
</div>

    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          
    <h3 id="brand" class="masthead-title">
      <a href="../../" title="Codename 'Sufficient Statistics'" rel="home">Codename 'Sufficient Statistics'</a>
    </h3>


        </div>
      </div>

      <div class="container content" id="content">
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="post-title p-name entry-title" itemprop="headline name"><a href="." class="u-url">Multilevel GANs</a></h1>

        
        <ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/adversarial-networks/" rel="tag">adversarial networks</a></li>
            <li><a class="tag p-category" href="../../categories/deep-learning/" rel="tag">deep learning</a></li>
            <li><a class="tag p-category" href="../../categories/generative-models/" rel="tag">generative models</a></li>
        </ul></header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Статьи:</p>
<ul>
<li>LapGAN: <a href="http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks%20Deep">Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. Denton et. al. 2015</a>
</li>
<li>StackGAN: <a href="https://arxiv.org/abs/1612.03242">Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks. Zhang et. al. 2016</a>
</li>
<li>SGAN: <a href="https://arxiv.org/abs/1612.04357">Stacked Generative Adversarial Networks. Huang et. al. 2016</a>
</li>
<li>Progressive GAN: <a href="https://arxiv.org/abs/1710.10196">Progressive Growing of GANs for Improved Quality, Stability and Variation. Karras et. al. 2017</a>
</li>
</ul>
<h1 id="мотивация">Мотивация</h1>
<p>В последнее время GAN-ы очень активно развиваются, и с их помощью удается получать изображения высокого визуального качества. При этом их обучение как правило очень дорогое, также у них есть много проблем с нестабильностью и сложностью подбора параметров — из-за этого генерация изображений высокого разрешения представляет большую сложность.</p>
<p>Две крупные проблемы, которые возникают: 1) на изображениях получается непонятная ерунда (высокого качества) вместо осмысленных объектов, 2) тяжело подобрать архитектуру, которая не сломается совсем. При этом эксперименты показывают, что генерация изображений низкого разрешения получается вполне осмысленной и более или менее стабильной, отсюда возникает идея делать несколько “уровней” GAN-ов для разных степеней подробности изображений (формальнее см. ниже). Здесь мы рассмотрим 4 статьи, архитектуры которых по моему мнению подходят под эту идею; статьи расположены в хронологическом порядке, и последняя из них позволяет получать изображения высокого качества разрешением в 1 мегапиксель (!).</p>
<h1 id="архитектуры-и-примеры">Архитектуры и примеры</h1>
<p>На все архитектуры мы будем смотреть с высокого уровня абстракции, то есть не будем подробно разбираться в целевых функциях и методах оптимизации.</p>
<h2 id="lapgan-2015">LapGAN (2015)</h2>
<p>В этой статье предлагается разложить изображения в пирамиду Лапласа (Laplacian pyramid), а потом на каждом уровне обучить отдельный GAN. Опишем, что такое пирамида Лапласа.</p>
<p>Обозначим <span class="math inline">\(d(\cdot)\)</span> — оператор, который размывает изображение и прореживает его пиксели через один, т.е. если на входе было изображение разрешения <span class="math inline">\(j \times j\)</span>, то на выходе будет изображение разрешения <span class="math inline">\(j/2 \times j/2\)</span>. Также введем оператор <span class="math inline">\(u(\cdot)\)</span>, который наоброт повышает разрешение изображения (каким-нибудь простым методом интерполяции), т.е. из изображения размера <span class="math inline">\(j \times j\)</span> получается изображение размера <span class="math inline">\(2j \times 2j\)</span>.</p>
<p>Пусть <span class="math inline">\(I\)</span> — входное изображение, для него сначала строится последовательность <span class="math inline">\([I_0, I_1, \ldots I_K]\)</span>, где <span class="math inline">\(I_0 = I, \; I_k = d(I_{k-1})\)</span>. Дальше берутся разности между уровнями, и получается пирамида Лапласа: <span class="math inline">\(h_k = I_k - u(I_{k+1})\)</span> для <span class="math inline">\(k = 1, \ldots, K-1\)</span>, и <span class="math inline">\(h_K = I_K\)</span>. Смысл этой пирамиды такой: на уровне <span class="math inline">\(h_0\)</span> находятся самые мелкие детали изображения (это разность между исходным изображением и его немного размытой версией), а далее на каждом уровне получаются все более общие детали, которые хранятся в меньшем разрешении. Вернуться обратно к исходному изображению можно по формуле: <span class="math inline">\(I_k = u(I_{k+1}) + h_k\)</span>.</p>
<p>Дальше все просто: 1) Преобразуем всю обучающую выборку в пирамиды, 2) Учим GAN на каждом уровне отдельно, 3) Генерируем пирамиды и из них обратно собираем изображения. На всех уровнях кроме первого обучается обусловленный GAN, который передает генератору не только шум, но и изображение с предыдущего уровня (дискриминатор тоже видит это изображение). Ниже картинки с архитектурой (плюс там можно посмотреть как выглядят уровни пирамиды).</p>
<p>Обучение:</p>
<p><img src="../../post-images/multilevel-gans/LapGAN-training.png" class="large"></p>
<p>Сэмплирование:</p>
<p><img src="../../post-images/multilevel-gans/LapGAN-sampling.png" class="large"></p>
<p>Эта архитектура позволяет подняться от разрешения ~32x32 до ~64x64, вот примеры сэмплов:</p>
<p><img src="../../post-images/multilevel-gans/LapGAN-examples.png"></p>
<p>Можно обучать и в более высоком разрешении, но на картинках получается ерунда (но по крайней мере не происходит коллапса).</p>
<h2 id="stackgan-и-sgan-2016">StackGAN и SGAN (2016)</h2>
<p>В этих двух статьях авторы отталкивались от более прямолинейной идеи: а давайте мы сделаем GAN, который генерирует изображения низкого разрешения, а потом обучим еще один GAN, который принимает изображения низкого разрешения и генерирует изображения высокого разрешения. При желании можно добавлять больше уровней. Разберем их постановки задач и архитектуры поподробнее.</p>
<h3 id="stackgan">StackGAN</h3>
<p>В этой статье рассматривается задача text-to-image, то есть они принимают на вход текст, делают из него эмбэдинг, и из него хотят генерировать картинки. Ниже архитектура, а потом комментарии к ней.</p>
<p><img src="../../post-images/multilevel-gans/StackGAN.png"></p>
<p>Комментарии:</p>
<ul>
<li>В предыдущем разделе мы обсуждали, что 64x64 тяжело обучать, и нужен LapGAN, а тут раз — и обучаем сразу 64x64, как так? На самом деле тут никакой магии нет: 1) визуальное качество получается низким, но это не страшно, главное чтобы были общие контуры, 2) стабильность достигается засчет наличия эмбедингов и Conditioning Augmentation (см. далее).</li>
<li>Conditioning Augmentation — трюк для стабилизации обучения на эмбэдингах текста (которые могут находиться очень далеко друг от друга в пространстве всех эмбэдингов). Идея состоит в том, чтобы из эмбединга получать среднее и дисперсию распределения, а потом из него сэмплировать. Таким образом один и тот же обучающий объект может порождать немного разные обуславливающие вектора.</li>
</ul>
<p>Сгенерированные примеры получаются хорошие, причем в разрешении уже 256x256. Ниже примеры, с результатами после первого GAN-а и после обоих, результат первого искусственно увеличен для удобства сравнения.</p>
<p><img src="../../post-images/multilevel-gans/StackGAN-examples.jpg"></p>
<h3 id="sgan">SGAN</h3>
<p>В этой статье результаты получились почему-то похуже, возможно дело в том, что рассматривалась исходная задача без входной информации. Архитектура тут значительно сложнее, а итоговые сэмплы разрешением не выше 32x32 (правда по куче метрик лучше всех классических GAN-ов).</p>
<p>Опишем в общих чертах архитектуру:</p>
<ul>
<li>Берется обычная сеть для классификации и из нее извлекаются представления через каждые <span class="math inline">\(K\)</span> слоев (она дальше называется энкодером).</li>
<li>Обучаем генераторы принимать эти представления и генерировать предыдущие представления (т.е. как бы обращаем процесс, получаем декодер).</li>
<li>При обучении используется взвешенная сумма кучи функций потерь: 1) качество дискриминатора, 2) качество реконструкции энкодер-декодер, 3) нижняя оценка на энтропию распределения генератора при фиксированном представлении (это чтобы шум не игнорировался).</li>
</ul>
<p>Можно полюбоваться на архитектуру, но подробно разбираться не будем:</p>
<p><img src="../../post-images/multilevel-gans/SGAN-architecture.png" class="large"></p>
<p>Как было сказано выше, примеры там в низком разрешении, поэтому их здесь не приводим (визуально непонятно, хорошие они или нет).</p>
<h2 id="progressivegan-2017">ProgressiveGAN (2017)</h2>
<p>В этой статье основная идея заключается в том, чтобы сначала обучать GAN для генерации изображения маленького разрешения (они стартуют с 4x4), а потом постепенно добавлять в него новые слои, которые увеличивают разрешение выходной картинки. Удобнее это смотреть на схеме:</p>
<p><img src="../../post-images/multilevel-gans/ProGAN-training.png"></p>
<p>Дискриминатор и генератор все время являются зеркальным отражением друг друга. После добавления новых слоев старые слои не замораживаются, но для того, чтобы новые слои (с изначально случайными весами) не ломали старые, они добавляются постепенно. То есть на выходе используется <span class="math inline">\(\alpha \cdot\)</span>(результат нового слоя)$ + (1-)$(увеличенный старый результат), где <span class="math inline">\(\alpha\)</span> плавно меняется от 0 до 1:</p>
<p><img src="../../post-images/multilevel-gans/ProGAN-fadein.png"></p>
<p>Дальше к этой схеме добавляется несколько трюков, это все обучается 20 дней на NVIDIA Tesla P100 GPU, и получаются вот такие результаты на датасете фотографий знаменитостей (это самые удачные примеры):</p>
<p><img src="../../post-images/multilevel-gans/ProGAN-examples-celeb.png"></p>
<p>У них есть еще много крутых примеров, их можно посмотреть в <a href="http://arxiv.org/abs/1710.10196">статье</a> или в <a href="https://youtu.be/XOxxPcy5Gr4">видео</a>.</p>
<h1 id="резюме">Резюме</h1>
<p>В целом такие многоуровневые GAN-ы можно рассматривать как форму регуляризации, которая тем не менее позволяет упрощать обучение и получать очень впечатляющие результаты. Хотя обычные GAN-ы тоже удается обучить для разрешения в 1 мегапиксель (например, <a href="https://arxiv.org/abs/1706.00082">тут</a>), ProgressiveGAN дает самые качественные из известных на данный момент результатов.</p>
    </div>

    <aside class="post-meta"><a class="post-author" href="../../authors/aleksei-umnov/">Алексей Умнов</a>
    <time class="post-date published dt-published" datetime="2017-12-08T09:10:03+03:00" itemprop="datePublished" title="08 декабря 2017">08 декабря 2017</time></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article>
</div>
    </div>
    <label for="sidebar-checkbox" class="sidebar-toggle"></label>
    
    
        <footer id="footer"><p>Contents © 2017         <a href="mailto:info@bayesgroup.ru">BayesGroup</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer><script src="../../assets/js/jquery.min.js"></script><script src="../../assets/js/moment-with-locales.min.js"></script><script src="../../assets/js/fancydates.js"></script><!-- fancy dates --><script>
    moment.locale("ru");
    fancydates(2, "DD.MM.YYYY");
    </script><!-- end fancy dates -->
</body>
</html>
