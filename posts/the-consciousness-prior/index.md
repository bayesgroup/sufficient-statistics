---
title: The Consciousness Prior
slug: the-consciousness-prior
date: 2017-09-26 20:56:03 UTC+03:00
author: Артём Соболев
tags: mathjax, deep learning, attention
link: https://arxiv.org/abs/1709.08568
---

Мини-заметка на 4 страницах о гипотетическом подходе к созданию RL агентов с механизмом сознания / изучению распутанных (disentangled) представлений, обильно политая баззвордом conscious (это слово в заметке встречается 41 раз! Сорок один! По десять раз на страницу, Карл!)

# Мотивация
Для выучивания распутанных представлений, т.е. таких, в которых одна компонента скрытого состояния влияет только на одно свойство рассматриваемого объекта (например, угол поворота лица по горизонали), предлагается завести т.н. сознающее состояние (conscious state), обращающее разреженное внимание (sparse attention) на первое скрытое состояние, выбирая только несколько его компонент и пытаясь сделать разумное утверждение о них, что бы это ни значило. В принципе, если две компоненты скрытого состояния регулируют одно и то же свойство, то мы по одному из них не сможем сделать разумных утверждений (однако, никаких гарантий, что этот фактор не свяжет поворт по горизонтали и по вертикали в поворот по диагонали, нет).

# "Математика"
Предполагается, что у нас есть последовательность наблюдений $s_t$ (как обычно в RL) и мы крутим поверх неё RNN'ку (какая вам больше нравится), генерирующую нам на каждом шаге выход $h_t$ – это и есть наше скрытое представление, которое мы хотим сделать максимально распутанным.

Теперь о том, как вычислять это самое сознающее состояние $c_t$: предлагается завести некую нейрость $C(h_t,c_{t−1},z_t)$, которая будет обращать разреженное внимание на компоненты $h_t$, пользуясь контекстом $c_{t−1}$, а ещё добавим стохастичности для большего веселья разведования (exploration). Теперь о том, как мы всё-таки хотели бы обучать это сознающее состояние. Было бы очень круто, если бы мы таким образом могли предсказывать будущее, например, пусть мы хотим в момент времени $t$ делать какое-то предсказание о будущем в виде $c_t$, а через $k$ шагов проверять его с помощью $h_{t+k}$. Поэтому вводим ещё одну нейросеть $V(h_t,c_{t−k})$, которая будет делать именно это. Правда, с каким лоссом её обучать – непонятно ¯\\\_(ツ)\_/¯

Экспериментов нет (во всей лабе из 100+ человек не нашлось желающих взяться за задачу?), но вы держитесь в заметке есть идеи о том, какие эксперименты можно было бы провести.

# Резюме
В общем-то интересные мысли о возможной архитектуре, которые, правда, нужно додумывать самостоятельно (особенно $V(h_t,c_{t−k})$. Но идеи без экспериментов – дело сомнительное.
